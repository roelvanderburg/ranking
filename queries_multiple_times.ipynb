{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpreting implicit feedback data for expert systems\n",
    "\n",
    "\n",
    "\n",
    "Plan: \n",
    "\n",
    "\n",
    "0.5) Clean code of rank monitor (Work-ahead for the logging of next sprint)\n",
    "\n",
    "1) Accurately Interpreting Clickthrough Data as Implicit Feedback (SIGIR 2016 Test Of Time Award)\n",
    "\t\n",
    "\n",
    "\tTrust bias   - > Bias to 'trust' engine click first reult\n",
    "\tQuality Bias - > If the relevance of the retrieved results decreases, \n",
    "\t\t\t users click on abstracts that are on average\n",
    "\t\t         less relevant\n",
    "\n",
    "\tExample set = S1 = {l1,. .. l7}\n",
    "\t\n",
    "\tS1 =    l1* l2 l3* l4 l5* l6 l7\n",
    "\n",
    "\t5 Strategies. \n",
    "\tClick > Skip Above, \n",
    "\tLast Click > Skip Above, \n",
    "\tClick > Earlier Click, \n",
    "\tClick > Skip Previous, \n",
    "\tClick > No Click Next\n",
    "\n",
    "2) Relative rankings to gold-set list\n",
    "\t2.1 Take set from SearchText that have been queried for ~200 or more times.\n",
    "\t2.2 Implement methodology from above paper.\n",
    "\t2.3 Implement graph methodology from other paper that builds on 1. \n",
    "\t\t2.3.1 Construct graph of relevance paths. \n",
    "\t\t2.3.2 Find largest connected graph. \n",
    "\n",
    "3) Delphi Questionnaires\n",
    "\tDoes this approach match with what Delphi Questionaire would give us. \n",
    "\n",
    "\n",
    "\n",
    "</b>\n",
    "\n",
    "\n",
    "\n",
    "To get a faceted search:\n",
    "\n",
    "# Facet Search: \n",
    "\n",
    "http://ec2-3-120-229-133.eu-central-1.compute.amazonaws.com:8080/solr/ACC_Logging_Slave/select?facet.field=SearchText&facet.mincount=200&facet=on&indent=on&q=EventID:164%20UserID:*&rows=0&wt=jsonueyr\n",
    "\n",
    "http://ec2-3-120-229-133.eu-central-1.compute.amazonaws.com:8080/solr/ACC_Logging_Slave/select?facet.field=SearchText&facet.mincount=200&facet=on&indent=on&q=EventID:164%20UserID:*%20AND%20ShortTimeStamp:[20181201%20TO%2020201201]&rows=0&wt=jsonueyr\n",
    "\n",
    "De query: \"unieke test query\"\n",
    "Aangeklikt: [3, 5, 7 17]  ->  (18-06-2019)\n",
    "Aangeklikt: [1,10]        ->  (18-06-2019) +5 min later\n",
    "Aangeklikt: [1,3,7]       ->  (18-06-2019) +25 min later\n",
    "Aangeklikt: [2,2,7,8]     ->  (21-06-2019) ~ 15:25\n",
    "\n",
    "De query: \"Unieke test query\"\n",
    "TO DO Aangeklikt: [1, 10]       ->  (21-06-2019) ~ 15:33 Maar later dan\n",
    "\n",
    "\n",
    "\n",
    "De Query: \"test information retrieval\"\n",
    "Aangeklikt: [2, 5, 8, 26] ->  (18-06-2019)\n",
    "Aangeklikt: [4, 12]       ->  (18-06-2019) + 5 min later\n",
    "Aangeklikt: [1, 2, 5]     ->  (18-06-2019) +25 min later\n",
    "Aangeklikt: [3, 4, 13]     ->  (21-06-2019) (15:33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "817bdba8d11e4a5b98f143cfadc882ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; } </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, average_precision_score\n",
    "import math\n",
    "import requests\n",
    "import os\n",
    "import itertools\n",
    "\n",
    "from urllib import *\n",
    "import json\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "from collections import Counter\n",
    "from tqdm import tqdm_notebook \n",
    "tqdm_notebook().pandas()\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from time import strftime, gmtime\n",
    "import datetime\n",
    "from datetimerange import DateTimeRange\n",
    "from datetime import timedelta  \n",
    "from  dateutil import parser\n",
    "\n",
    "\n",
    "# Greedy IDE completion \n",
    "%config IPCompleter.greedy=True\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; } </style>\"))\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 30)\n",
    "\n",
    "\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Graph-building packages\n",
    "import community\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Request dataframe from solr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_into_dataframe(rows= 100, query= '*:*', sort=''):\n",
    "    \"\"\"\n",
    "    :param rows: amount of rows to request\n",
    "    :param query: string to query\n",
    "    :param sort: string to sort the request eg. sort='ShortTimeStamp desc'\n",
    "    \"\"\"\n",
    "    \n",
    "    url = 'http://ec2-3-120-229-133.eu-central-1.compute.amazonaws.com:8080/solr' \\\n",
    "    '/ACC_Logging_Slave/select?indent=on&q={}&rows={}&sort={}&start=0&wt=json'.format(query,rows,sort)\n",
    "\n",
    "    print(url)\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Transform the request into a json\n",
    "    response = response.json()\n",
    "    response = response['response']['docs']\n",
    "     \n",
    "    return pd.DataFrame(response)\n",
    "     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_27_frame(rows=100000000, from_disk=True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Get all the logging with a clicked documentPosition. \n",
    "    DocumentPosition clicked is logged since 12-2018\n",
    "    :param rows: query string\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    \n",
    "    if from_disk:\n",
    "        return pd.read_hdf('./data_rank/df27_full')\n",
    "    \n",
    "    else:\n",
    "        df_27_bitcoin = request_into_dataframe(rows=rows, query='EventID:27 AND DocumentPosition:*')\n",
    "        df_27_bitcoin.to_hdf('./data_rank/df27_full', key='test', mode='w')\n",
    "        \n",
    "    return df_27_bitcoin \n",
    " \n",
    "\n",
    "def get_16_frame(search_text = '*', rows=1000000000) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Get every search log from people with a UserID:* \n",
    "    :param search_text: query string\n",
    "    :param rows: number of rows to get\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    \n",
    "   \n",
    "    df_164_bitcoin = request_into_dataframe(query='EventID:164 AND ShortTimeStamp:[20181201 TO 20201201] AND UserID:* AND SearchText:\"{}\" \\\n",
    "                                                        '.format(search_text,search_text), rows = rows)     \n",
    "    \n",
    "    if search_text != search_text.lower():\n",
    "        df_164_bitcoin_lowercase = request_into_dataframe(query='EventID:164 AND ShortTimeStamp:[20181201 TO 20201201] AND UserID:* AND SearchText:\"{}\" \\\n",
    "                                                            '.format(search_text.lower(),search_text.lower()), rows = rows)     \n",
    "        df = pd.concat([df_164_bitcoin, df_164_bitcoin_lowercase])\n",
    "    else:\n",
    "        df = df_164_bitcoin\n",
    "    \n",
    "    \n",
    "#     try:\n",
    "#         # Keep only filterpath is NaN so only searches regular engine ie. no filtered searches. \n",
    "#         df = df[pd.isna(df['FilterPath'])]\n",
    "#     except ValueError:\n",
    "#         print('Empty dataframe')\n",
    "        \n",
    "    # Inster an empty column with to be filled document positions \n",
    "    df['DocumentPosition'] = df.progress_apply(lambda x: [], axis=1)\n",
    "    \n",
    "    df.to_hdf('./multiple_query/df164_full', key='test', mode='w')\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# get_16_frame('unieke test query', rows=1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_currentdir():\n",
    "    \"\"\"\n",
    "    Helper function to print contents of current directory and /data/ dir.\n",
    "    \"\"\"\n",
    "    currentdir = Path('./data/')\n",
    "    display([file for file in currentdir.glob('*')])\n",
    "    display([file for file in Path('./').glob('*')])\n",
    "    display([file for file in Path('./multiple_query/').glob('*')])\n",
    "\n",
    "\n",
    "# list_currentdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_in_timerange(timestamp : datetime.datetime, query = pd.DataFrame, df_27 = pd.DataFrame) -> list:\n",
    "    \"\"\"\n",
    "    Check if the there are clickedobjects within + and - 5 minutes from the query\n",
    "    timestamp: object from the dateutil parser library\n",
    "    :param timestamp:\n",
    "    :param query:\n",
    "    :param df_27:\n",
    "    \"\"\"\n",
    "    \n",
    "    timestamp_27 = [parser.parse(time, fuzzy_with_tokens=False) for time in df_27['TimeStamp']]\n",
    "    \n",
    "    doc_pos = []\n",
    "    doc_ids = []\n",
    "    for idx, stamp_27 in enumerate(timestamp_27):\n",
    "\n",
    "        if timestamp in DateTimeRange(stamp_27, stamp_27 + timedelta(minutes=5)):\n",
    "            \n",
    "            doc_pos.append(df_27['DocumentPosition'].iloc[idx])\n",
    "            doc_ids.append(df_27['DocumentID'].iloc[idx])\n",
    "    \n",
    "    return doc_pos, doc_ids\n",
    "    \n",
    "\n",
    "def check_and_concat(df_164: pd.DataFrame, df_27: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Check both dataframes get clicks from 27 and add these to the original query in 164\n",
    "    :param df_164: dataframe containing the 164 log\n",
    "    :param df_27: dataframe containing the 27 log\n",
    "    \"\"\"\n",
    "    \n",
    "    final_pos = [] \n",
    "    final_ids = []\n",
    "    for idx, (df_shape, df_164_group) in enumerate(tqdm(df_164.groupby(by=['UserID','ShortTimeStamp']) , desc='Looping through queries')):\n",
    "        \n",
    "        # Check timestamps for dataframe \n",
    "        timestamps = [parser.parse(time, fuzzy_with_tokens=False) for time in df_164_group['TimeStamp'].tolist()]\n",
    "\n",
    "        # Ony check searches from the specific user\n",
    "        temp_27 = df_27[df_27['UserID'] == df_164_group['UserID'].iloc[0]]\n",
    "\n",
    "        # Check every single timestamp for all the seperate events\n",
    "        for stamp in timestamps:\n",
    "            doc_pos, doc_ids = check_in_timerange(stamp, df_164_group, temp_27)\n",
    "            final_pos.append(doc_pos)\n",
    "            final_ids.append(doc_ids)\n",
    "\n",
    "    df_164['DocumentPosition'] = final_pos\n",
    "    df_164['DocumentID'] = final_ids\n",
    "    \n",
    "    return df_164\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilities from Figure 1, from paper: \"Generating Labels from Clicks\"\n",
    "probs = {1:  [1,1,0.55,0.42,0.3,0.22,0.15,0.1,0.08,0.05,0,0],\n",
    "         2:  [1,1,1,0.49,0.35,0.29,0.2,0.11,0.10,0.10,0,0], \n",
    "         3:  [1,1,1,1,0.6,0.42,0.2,0.5,0.5,0.5,0,0],\n",
    "         4:  [1,1,1,1,1,0.4,0.33,0.18,0.17,0.16,0,0],\n",
    "         5:  [1,1,1,1,1,1,0.33,0.15,0.08,0.05,0,0],\n",
    "         6:  [1,1,1,1,1,1,1,0.15,0,0,0,0],\n",
    "         7:  [1,1,1,1,1,1,1,1,0.42,0.22,0,0],\n",
    "         8:  [1,1,1,1,1,1,1,1,1,0.22,0,0],\n",
    "         9:  [1,1,1,1,1,1,1,1,1,0.92,0,0],\n",
    "         10: [1] * 12,\n",
    "         11: [1] * 12,\n",
    "         12: [1] * 12\n",
    "         }\n",
    "\n",
    "\n",
    "def get_clicked_list(df = pd.DataFrame) -> [list]:\n",
    "    \"\"\"\n",
    "    :param df: pandas dataframe with clicked positions given query\n",
    "    :return: list of clicked links \n",
    "    \"\"\"\n",
    "\n",
    "    clicks = df['DocumentPosition'].to_list()\n",
    "    \n",
    "    # Convert clicks to a set to leave out double clicks in a session. \n",
    "    clicks = [list(set(pos)) for pos in clicks]\n",
    "\n",
    "    # Only keep clicks in the range 1 - 12. Ie. remove outlier clicks ie. we do not have probabilities to discount further clicks. \n",
    "    clicks = list(filter(lambda x: x != [], map(lambda x: [i for i in x if i <= 12], clicks)))\n",
    "    \n",
    "    return clicks\n",
    "    \n",
    "def make_edges_r1(df: pd.DataFrame, probs: dict) -> [tuple]:\n",
    "    \"\"\"\n",
    "    Generate the edges to construct a graph\n",
    "    It does by Rule 1: Click > skip above\n",
    "    :param df:\n",
    "    :param probs:\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    clicks_list = get_clicked_list(df)\n",
    "    \n",
    "    # From list of lists to single clicks -> treat each click as\n",
    "    clicks_list = list(itertools.chain.from_iterable(clicks_list))\n",
    "    edges = []\n",
    "    for click in clicks_list:\n",
    "        dummy_probabilities = []\n",
    "        for i in range(1,12):\n",
    "            if i != click and probs[click][i] > 0:\n",
    "                dummy_probabilities.append((i,click, probs[click][i]))\n",
    "        edges.extend(dummy_probabilities)\n",
    "    display(edges)\n",
    "        \n",
    "    return edges\n",
    "\n",
    "def make_edges_r2(df: pd.DataFrame, probs: dict) -> [tuple]:\n",
    "    \"\"\"\n",
    "    Generate the edges to construct a graph\n",
    "    It does by Rule 2: Last click > skip above\n",
    "    :param df:\n",
    "    :param probs:\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    clicks_list = get_clicked_list(df)\n",
    "    \n",
    "    # From list of lists to single clicks -> treat each click as\n",
    "    edges = []\n",
    "    for clicks in clicks_list:\n",
    "        # Takes last click in clicks list\n",
    "        click = clicks[-1]\n",
    "        dummy_probabilities = []\n",
    "\n",
    "        for i in range(1, 12):\n",
    "            if i not in clicks and i != click and probs[click][i] > 0:\n",
    "                  dummy_probabilities.append((i,click, probs[click][i]))\n",
    "        edges.extend(dummy_probabilities)\n",
    "    \n",
    "    return edges\n",
    "\n",
    "def make_edges_r3(df: pd.DataFrame, probs: dict) -> [tuple]:\n",
    "    \"\"\"\n",
    "    Generate the edges to construct a graph\n",
    "    NOT PROBABILISITC\n",
    "    It does by Rule 3: Cick > Earlier Click\n",
    "    :param df:\n",
    "    :param probs:\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    # From list of lists to single clicks -> treat each click as\n",
    "    edges = []\n",
    "    for clicks in clicks_list:\n",
    "\n",
    "        dummy_probabilities = []\n",
    "\n",
    "        # Takes clicks from position 2 forward\n",
    "        for idx, click in enumerate(clicks):\n",
    "            if idx > 0:\n",
    "                ranges = np.arange(0,idx)\n",
    "                for i in ranges:\n",
    "                    dummy_probabilities.append((clicks[i], clicks[idx], 1))\n",
    "\n",
    "        edges.extend(dummy_probabilities)\n",
    "\n",
    "    return edges\n",
    "\n",
    "\n",
    "def make_edges_r4(df: pd.DataFrame, probs: dict) -> [tuple]:\n",
    "    \"\"\"\n",
    "    Generate the edges to construct a graph\n",
    "    NOT PROBABILISITC\n",
    "    It does by Rule 3: Cick > Earlier Click\n",
    "    :param df:\n",
    "    :param probs:\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    # From list of lists to single clicks -> treat each click as\n",
    "    edges = []\n",
    "    for clicks in clicks_list:\n",
    "\n",
    "        dummy_probabilities = []\n",
    "\n",
    "        # Takes clicks from position 2 forward\n",
    "        for idx, click in enumerate(clicks):\n",
    "            if idx > 0:\n",
    "                ranges = np.arange(0,idx)\n",
    "                for i in ranges:\n",
    "                    dummy_probabilities.append((clicks[i], clicks[idx], 1))\n",
    "\n",
    "        edges.extend(dummy_probabilities)\n",
    "\n",
    "    return edges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_relevance_graph(edges: [tuple]):\n",
    "    \"\"\"\n",
    "    Helper function to create a relevance graph between relevant documents. \n",
    "    :param edges: lis of edges between two documents and their signal strength\n",
    "    \"\"\"\n",
    "    DG = nx.DiGraph()\n",
    "    DG.add_weighted_edges_from(edges)\n",
    "\n",
    "    # Forcing a layout \n",
    "    pos = nx.spring_layout(DG)\n",
    "\n",
    "    # Make a label dictionary: {} for labeling of graph \n",
    "    new_labels = dict(map(lambda x: ((x[0],x[1]), x[2]['weight']), DG.edges(data=True)))\n",
    "    \n",
    "    nx.draw_networkx(DG, pos=pos,alpha=0.5)\n",
    "    nx.draw_networkx_edge_labels(DG, pos=pos, edge_labels=new_labels)\n",
    "    nx.draw_networkx_edge_labels(DG, pos=pos)\n",
    "    plt.title('Pair-wise network')\n",
    "    plt.savefig('Large-graph')\n",
    "    plt.show()\n",
    "\n",
    "    dicto = nx.pagerank(DG)\n",
    "\n",
    "    print(\"Before sorting: \\n\", dicto) \n",
    "    dicto = sorted(dicto.items(), key=lambda x: x[1], reverse=True)\n",
    "    print(\"After sorting: \\n\", dicto)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get dataframes: \n",
      "Got dataframe 27\n",
      "http://ec2-3-120-229-133.eu-central-1.compute.amazonaws.com:8080/solr/ACC_Logging_Slave/select?indent=on&q=EventID:164 AND ShortTimeStamp:[20181201 TO 20201201] AND UserID:* AND SearchText:\"AVG\"                                                         &rows=10000&sort=&start=0&wt=json\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "HTTPConnectionPool(host='ec2-3-120-229-133.eu-central-1.compute.amazonaws.com', port=8080): Max retries exceeded with url: /solr/ACC_Logging_Slave/select?indent=on&q=EventID:164%20AND%20ShortTimeStamp:[20181201%20TO%2020201201]%20AND%20UserID:*%20AND%20SearchText:%22AVG%22%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20&rows=10000&sort=&start=0&wt=json (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe8bd7cad68>: Failed to establish a new connection: [Errno 110] Connection timed out',))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    140\u001b[0m             conn = connection.create_connection(\n\u001b[0;32m--> 141\u001b[0;31m                 (self.host, self.port), self.timeout, **extra_kw)\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTimeoutError\u001b[0m: [Errno 110] Connection timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    600\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1238\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1284\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1233\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1234\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    963\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 964\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    965\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    149\u001b[0m             raise NewConnectionError(\n\u001b[0;32m--> 150\u001b[0;31m                 self, \"Failed to establish a new connection: %s\" % e)\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x7fe8bd7cad68>: Failed to establish a new connection: [Errno 110] Connection timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    439\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m                 )\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    638\u001b[0m             retries = retries.increment(method, url, error=e, _pool=self,\n\u001b[0;32m--> 639\u001b[0;31m                                         _stacktrace=sys.exc_info()[2])\n\u001b[0m\u001b[1;32m    640\u001b[0m             \u001b[0mretries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='ec2-3-120-229-133.eu-central-1.compute.amazonaws.com', port=8080): Max retries exceeded with url: /solr/ACC_Logging_Slave/select?indent=on&q=EventID:164%20AND%20ShortTimeStamp:[20181201%20TO%2020201201]%20AND%20UserID:*%20AND%20SearchText:%22AVG%22%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20&rows=10000&sort=&start=0&wt=json (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe8bd7cad68>: Failed to establish a new connection: [Errno 110] Connection timed out',))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-4df914a2768b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-4df914a2768b>\u001b[0m in \u001b[0;36mstart_search\u001b[0;34m(query_str)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdf_27\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_27_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfrom_disk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Got dataframe 27\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mdf_164\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_16_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_text\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mquery_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loaded both frames\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-f64be4715034>\u001b[0m in \u001b[0;36mget_16_frame\u001b[0;34m(search_text, rows)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mdf_164_bitcoin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequest_into_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'EventID:164 AND ShortTimeStamp:[20181201 TO 20201201] AND UserID:* AND SearchText:\"{}\"                                                         '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msearch_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msearch_text\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0msearch_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-5b739cf15831>\u001b[0m in \u001b[0;36mrequest_into_dataframe\u001b[0;34m(rows, query, sort)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Transform the request into a json\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    506\u001b[0m         }\n\u001b[1;32m    507\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    506\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mClosedPoolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPConnectionPool(host='ec2-3-120-229-133.eu-central-1.compute.amazonaws.com', port=8080): Max retries exceeded with url: /solr/ACC_Logging_Slave/select?indent=on&q=EventID:164%20AND%20ShortTimeStamp:[20181201%20TO%2020201201]%20AND%20UserID:*%20AND%20SearchText:%22AVG%22%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20&rows=10000&sort=&start=0&wt=json (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe8bd7cad68>: Failed to establish a new connection: [Errno 110] Connection timed out',))"
     ]
    }
   ],
   "source": [
    "def start_search(query_str='AVG') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    :param: query_str query string to request clicks for \n",
    "    :return: DataFrame to \n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Get dataframes: \")\n",
    "    df_27 = get_27_frame(rows=10000000,from_disk=True)\n",
    "    print(\"Got dataframe 27\")\n",
    "    df_164 = get_16_frame(search_text= query_str, rows=10000)\n",
    "    print(\"Loaded both frames\")\n",
    "    \n",
    "    display(df_27)\n",
    "    display(df_164)\n",
    "\n",
    "    df = check_and_concat(df_164=df_164, df_27=df_27)\n",
    "    \n",
    "    # Remove events that did not have a single click\n",
    "    df = df[df['DocumentPosition'].str.len() != 0]\n",
    "    df = df[pd.isna(df['FilterPath'])]\n",
    "\n",
    "    \n",
    "    print(\"shape dataframe\", df.shape)\n",
    "    \n",
    "    # Make edges & construct relevance graph \n",
    "    edges = make_edges_r1(df, probs)\n",
    "    \n",
    "    # Display some edges\n",
    "    edges[0][:10]\n",
    "    create_relevance_graph(edges=edges)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df = start_search()\n",
    "df\n",
    "\n",
    "# df['DocumentPosition'].tolist()\n",
    "\n",
    "# number = df.progress_apply(lambda x: [{click : [docid]} for click, docid in zip(df['DocumentPosition'].tolist(), df['DocumentID'].tolist())] , axis=1)\n",
    "\n",
    "# df.to_hdf('./multiple_query/df27_{}'.format('Full concat'), key='test', mode='w')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_27 = get_27_frame(rows=10000000,from_disk=True)\n",
    "df_27 = df_27[(df_27['SearchText'] == 'AVG' ) | (df_27['SearchText'] == 'avg' )]\n",
    "\n",
    "   \n",
    "new_cols = ['UserID', 'DocumentID', 'DocumentPosition', 'DocumentURL', 'EventID', 'ID',\n",
    "                   'SearchTypeID', 'ShortTimeStamp', 'TimeStamp', 'SearchText']\n",
    "\n",
    "df_27 = df_27[new_cols]\n",
    "\n",
    "df_27.sort_values(by=['DocumentPosition'])\n",
    "df_27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(1,1000)):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
